{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85144425-5543-4cb5-b77a-bd5e5e5cd399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required artifacts are found. Notebook is ready\n",
      "Final model selection artifact found: /home/tl/stock-news-sentiment-bert-finbert/artifacts/results/comparison/final_model_selection.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT/\"src\"))\n",
    "\n",
    "# Startup checks\n",
    "from startup_checks import ensure_project_dirs, check_required_artifacts, check_required_final_selection\n",
    "\n",
    "ensure_project_dirs()\n",
    "# tokenization_config.json, comparison artifacts and BERT/FinBERT artifacts are required\n",
    "check_required_artifacts()\n",
    "\n",
    "check_required_final_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88207d1d-eca4-4f41-a239-496de5a4b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BERT_KEY, FINBERT_KEY\n",
    "from analysis import (\n",
    "    load_model_artifacts, build_metrics_comparison_table, get_confusion_matrix, \n",
    "    top_confusions, classification_report_to_df\n",
    ")\n",
    "from artifacts_utils import load_final_model_selection, get_best_model_dir, load_tokenization_config\n",
    "from inference import prepare_inference_context, predict\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec20a4d-997c-4d3c-89d2-6d74d2695f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model selection:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'selected_model': {'model_key': 'finbert', 'model_id': 'ProsusAI/finbert'},\n",
       " 'selection_criteria': {'primary_metric': 'macro_f1',\n",
       "  'split': 'val',\n",
       "  'decision_rule': 'max',\n",
       "  'implicit_decision_rule': {'type': 'prefer_model',\n",
       "   'model_key': 'bert-base',\n",
       "   'when': 'score_tie'}},\n",
       " 'scores': {'bert-base': {'val': {'macro_f1': 0.7415754421031572,\n",
       "    'weighted_f1': 0.7975689752727669},\n",
       "   'test': {'macro_f1': 0.7521942203266261,\n",
       "    'weighted_f1': 0.8079636171969878}},\n",
       "  'finbert': {'val': {'macro_f1': 0.7751226453612198,\n",
       "    'weighted_f1': 0.8142125444355713},\n",
       "   'test': {'macro_f1': 0.7675000443474712,\n",
       "    'weighted_f1': 0.8122094310469596}}},\n",
       " 'environment': {'tokenization_config': {'baseline_max_length': 96,\n",
       "   'max_length': 96,\n",
       "   'padding': 'max_length',\n",
       "   'truncation': True,\n",
       "   'selection_method': 'truncation_efficiency_tradeoff',\n",
       "   'truncation_threshold_pct': 1.0},\n",
       "  'bert-base': {'label_order': ['negative', 'neutral', 'positive'],\n",
       "   'label_to_id': {'negative': 0, 'neutral': 1, 'positive': 2},\n",
       "   'id_to_label': {'0': 'negative', '1': 'neutral', '2': 'positive'}},\n",
       "  'finbert': {'label_order': ['negative', 'neutral', 'positive'],\n",
       "   'label_to_id': {'negative': 0, 'neutral': 1, 'positive': 2},\n",
       "   'id_to_label': {'0': 'negative', '1': 'neutral', '2': 'positive'}}},\n",
       " 'metadata': {'created_at': '2025-12-29T15:59:40.415005',\n",
       "  'pipeline_stage': 'model_selection'},\n",
       " 'notes': 'Final model selected based on validation macro F1-score'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner: finbert\n",
      "Winner HF model_id: ProsusAI/finbert\n",
      "Primary metric: macro_f1\n",
      "Selection split: val\n"
     ]
    }
   ],
   "source": [
    "# Load final model selection (winner)\n",
    "final_selection = load_final_model_selection()\n",
    "\n",
    "print(\"Final model selection:\")\n",
    "display(final_selection)\n",
    "winner = final_selection[\"selected_model\"][\"model_key\"]\n",
    "winner_id = final_selection[\"selected_model\"][\"model_id\"]\n",
    "primary_metric = final_selection[\"selection_criteria\"][\"primary_metric\"]\n",
    "selection_split = final_selection[\"selection_criteria\"][\"split\"]\n",
    "\n",
    "print(\"\\nWinner:\", winner)\n",
    "print(\"Winner HF model_id:\", winner_id)\n",
    "print(\"Primary metric:\", primary_metric)\n",
    "print(\"Selection split:\", selection_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d983d9ad-5947-4841-9293-c69156899b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT and FinBERT artifacts\n",
    "bert_art = load_model_artifacts(BERT_KEY)\n",
    "finbert_art = load_model_artifacts(FINBERT_KEY)\n",
    "\n",
    "model_artifacts_map = {\n",
    "    BERT_KEY: bert_art,\n",
    "    FINBERT_KEY: finbert_art\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2958d9-e9f2-4c20-89eb-6896d8f03338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_macro_f1</th>\n",
       "      <th>eval_weighted_f1</th>\n",
       "      <th>eval_macro_precision</th>\n",
       "      <th>eval_weighted_precision</th>\n",
       "      <th>eval_macro_recall</th>\n",
       "      <th>eval_weighted_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base</td>\n",
       "      <td>val</td>\n",
       "      <td>0.48184</td>\n",
       "      <td>0.796233</td>\n",
       "      <td>0.741575</td>\n",
       "      <td>0.797569</td>\n",
       "      <td>0.735577</td>\n",
       "      <td>0.801038</td>\n",
       "      <td>0.749504</td>\n",
       "      <td>0.796233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finbert</td>\n",
       "      <td>val</td>\n",
       "      <td>0.42835</td>\n",
       "      <td>0.806507</td>\n",
       "      <td>0.775123</td>\n",
       "      <td>0.814213</td>\n",
       "      <td>0.761411</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.806507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model split  eval_loss  eval_accuracy  eval_macro_f1  eval_weighted_f1  \\\n",
       "0  bert-base   val    0.48184       0.796233       0.741575          0.797569   \n",
       "1    finbert   val    0.42835       0.806507       0.775123          0.814213   \n",
       "\n",
       "   eval_macro_precision  eval_weighted_precision  eval_macro_recall  \\\n",
       "0              0.735577                 0.801038           0.749504   \n",
       "1              0.761411                 0.837464           0.811377   \n",
       "\n",
       "   eval_weighted_recall  \n",
       "0              0.796233  \n",
       "1              0.806507  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics comparison (report only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_macro_f1</th>\n",
       "      <th>eval_weighted_f1</th>\n",
       "      <th>eval_macro_precision</th>\n",
       "      <th>eval_weighted_precision</th>\n",
       "      <th>eval_macro_recall</th>\n",
       "      <th>eval_weighted_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base</td>\n",
       "      <td>test</td>\n",
       "      <td>0.438863</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.752194</td>\n",
       "      <td>0.807964</td>\n",
       "      <td>0.744269</td>\n",
       "      <td>0.814187</td>\n",
       "      <td>0.763485</td>\n",
       "      <td>0.805128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finbert</td>\n",
       "      <td>test</td>\n",
       "      <td>0.419923</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.767500</td>\n",
       "      <td>0.812209</td>\n",
       "      <td>0.755469</td>\n",
       "      <td>0.835820</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.803419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model split  eval_loss  eval_accuracy  eval_macro_f1  eval_weighted_f1  \\\n",
       "0  bert-base  test   0.438863       0.805128       0.752194          0.807964   \n",
       "1    finbert  test   0.419923       0.803419       0.767500          0.812209   \n",
       "\n",
       "   eval_macro_precision  eval_weighted_precision  eval_macro_recall  \\\n",
       "0              0.744269                 0.814187           0.763485   \n",
       "1              0.755469                 0.835820           0.801047   \n",
       "\n",
       "   eval_weighted_recall  \n",
       "0              0.805128  \n",
       "1              0.803419  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare metrics table for macro and weighted\n",
    "metric_keys = [\n",
    "    \"eval_loss\", \"eval_accuracy\",\n",
    "    \"eval_macro_f1\", \"eval_weighted_f1\",\n",
    "    \"eval_macro_precision\", \"eval_weighted_precision\",\n",
    "    \"eval_macro_recall\", \"eval_weighted_recall\"\n",
    "]\n",
    "\n",
    "df_val = build_metrics_comparison_table(\n",
    "    model_artifacts_map=model_artifacts_map,\n",
    "    split=\"val\",\n",
    "    metric_keys=metric_keys\n",
    ")\n",
    "\n",
    "df_test = build_metrics_comparison_table(\n",
    "    model_artifacts_map=model_artifacts_map,\n",
    "    split=\"test\",\n",
    "    metric_keys=metric_keys\n",
    ")\n",
    "\n",
    "print(\"Validation metrics comparison:\")\n",
    "display(df_val)\n",
    "\n",
    "print(\"Test metrics comparison (report only):\")\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef44d872-42ee-4da3-b314-92aa6ac2b54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.503876</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.927481</td>\n",
       "      <td>0.776358</td>\n",
       "      <td>0.845217</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.755469</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.767500</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.835820</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.812209</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  precision    recall        f1  support\n",
       "0      negative   0.503876  0.755814  0.604651     86.0\n",
       "1       neutral   0.927481  0.776358  0.845217    313.0\n",
       "2      positive   0.835052  0.870968  0.852632    186.0\n",
       "3     macro avg   0.755469  0.801047  0.767500    585.0\n",
       "4  weighted avg   0.835820  0.803419  0.812209    585.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Per-class performance\n",
    "winner_art = bert_art if winner == BERT_KEY else finbert_art\n",
    "\n",
    "df_winner_test_cr = classification_report_to_df(winner_art, \"test\")\n",
    "\n",
    "label_order = winner_art[\"label_map\"][\"label_order\"]\n",
    "custom_order = label_order + [\"macro avg\", \"weighted avg\"]\n",
    "df_winner_test_cr[\"label\"] = pd.Categorical(df_winner_test_cr[\"label\"], categories=custom_order, ordered=True)\n",
    "\n",
    "display(df_winner_test_cr.sort_values([\"label\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6d20d0-64e2-4c04-a222-9fa3aceb5f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner CM normalize mode: true\n",
      "Label order: ['negative', 'neutral', 'positive']\n",
      "Confusion matrix:\n",
      " [[0.75581395 0.05813953 0.18604651]\n",
      " [0.17252396 0.77635783 0.05111821]\n",
      " [0.05376344 0.07526882 0.87096774]]\n",
      "CM shape: (3, 3)\n",
      "Top confusions (winner, test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_label</th>\n",
       "      <th>y_pred_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  y_true_label y_pred_label  count\n",
       "0      neutral     negative     54\n",
       "1     negative     positive     16\n",
       "2      neutral     positive     16\n",
       "3     positive      neutral     14\n",
       "4     positive     negative     10\n",
       "5     negative      neutral      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix and Top confusion\n",
    "cm = get_confusion_matrix(winner_art, \"test\")\n",
    "cm_norm = winner_art[\"evaluation\"][\"test\"][\"metadata\"][\"confusion_matrix_normalize\"]\n",
    "\n",
    "print(\"Winner CM normalize mode:\", cm_norm)\n",
    "print(\"Label order:\", label_order)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"CM shape:\", cm.shape)\n",
    "\n",
    "df_top = top_confusions(winner_art[\"predictions\"][\"test\"])\n",
    "print(\"Top confusions (winner, test):\")\n",
    "display(df_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51dd3612-7e61-4ee6-8336-c201a90d0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from: /home/tl/stock-news-sentiment-bert-finbert/artifacts/models/best/finbert\n",
      "Loaded model config id2label: {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "Loaded model config label2id: {'negative': 0, 'neutral': 1, 'positive': 2}\n"
     ]
    }
   ],
   "source": [
    "# Load best model from artifacts\n",
    "best_dir = get_best_model_dir(winner)\n",
    "print(\"Loading best model from:\", best_dir)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(best_dir, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(best_dir)\n",
    "\n",
    "print(\"Loaded model config id2label:\", model.config.id2label)\n",
    "print(\"Loaded model config label2id:\", model.config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8cb40b-0daa-418f-b2a5-d8bf5223833a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred_id</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>prob_negative</th>\n",
       "      <th>prob_neutral</th>\n",
       "      <th>prob_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The company reported strong earnings and raise...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.022080</td>\n",
       "      <td>0.972461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The outlook is uncertain and investors remain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.313208</td>\n",
       "      <td>0.664312</td>\n",
       "      <td>0.022481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The stock is plunged after disappointing results.</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.633271</td>\n",
       "      <td>0.353327</td>\n",
       "      <td>0.013402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pred_id pred_label  \\\n",
       "0  The company reported strong earnings and raise...        2   positive   \n",
       "1  The outlook is uncertain and investors remain ...        1    neutral   \n",
       "2  The stock is plunged after disappointing results.        0   negative   \n",
       "\n",
       "   prob_negative  prob_neutral  prob_positive  \n",
       "0       0.005459      0.022080       0.972461  \n",
       "1       0.313208      0.664312       0.022481  \n",
       "2       0.633271      0.353327       0.013402  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max_length: 96\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "token_cfg = load_tokenization_config()\n",
    "\n",
    "texts = [\n",
    "    \"The company reported strong earnings and raised guidance.\",\n",
    "    \"The outlook is uncertain and investors remain cautious.\",\n",
    "    \"The stock is plunged after disappointing results.\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ctx = prepare_inference_context(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    max_length=token_cfg[\"max_length\"]\n",
    ")\n",
    "\n",
    "df_inference = predict(\n",
    "    texts,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    ctx=ctx\n",
    ")\n",
    "\n",
    "display(df_inference)\n",
    "print(\"Using max_length:\", token_cfg[\"max_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0303b8d9-035e-4f6b-8c6c-49ef994ab9bb",
   "metadata": {},
   "source": [
    "## Summary - Final Model Inference\n",
    "\n",
    "### Objective\n",
    "To load the selected final model from persisted artifacts and demonstrate a clean, reproducible, and deployment-ready inference workflow, using the same preprocessing configuration and label mappings defined during training and model selection.\n",
    "\n",
    "### Work Performed\n",
    "- Prepared an explicit InferenceContext encapsulating to explicitly separate inference configuration from model logic\n",
    "  - execution device (CPU / GPU)\n",
    "  - maximum token length\n",
    "  - validated id2label mapping\n",
    "- Verified inference outputs using sample, unseen input texts\n",
    "\n",
    "### Key Decisions\n",
    "- Reused training-time artifacts (tokenization config, label map) to avoid configuration drift\n",
    "\n",
    "### Results\n",
    "- Successfully generated predictions and calibrated class probabilities for unseen texts\n",
    "\n",
    "### Artifacts Used\n",
    "- Final model selection:\n",
    "  - **artifacts/results/comparison/final_model_selection.json**\n",
    "- Best model checkpoint (winner):\n",
    "  - **artifacts/models/best/winner_model_key/**\n",
    "- Shared preprocessing config:\n",
    "  - **artifacts/preprocessing/tokenization_config.json**\n",
    "- Label mappings:\n",
    "  - **artifacts/preprocessing/winner_model_key/label_map.json**\n",
    "\n",
    "### Takeaway\n",
    "This notebook completes the end-to-end pipeline by demonstrating how a trained and selected Transformer model can be safely and consistently used for inference.\n",
    "The design emphasizes artifact-driven reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ce53f-4f8b-4f17-8f98-5a48b78c0f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce3ef9-b39a-4236-a2ed-8ecd61c127ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
